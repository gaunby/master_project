{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_from_disk\n",
    "import torch\n",
    "sys.path.insert(0,'/zhome/94/5/127021/speciale/master_project')\n",
    "from src.models.hate_tcav.TCAV import get_preds_tcavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zhome/94/5/127021/speciale/master_project/src/models/hate_tcav/Roberta_model_data.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/zhome/94/5/127021/speciale/master_project/src/models/hate_tcav/Roberta_model_data.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels[idx])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from src.data.embedding_layer_rep import create_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = 'wikipedia_split'\n",
    "model_layer = '11'\n",
    "num_random_set = 500\n",
    "num_ex_in_set = 150\n",
    "\n",
    "name = f'tensor_{Data}_on_{model_layer}_layer_{num_random_set}_sets_with_{num_ex_in_set}'\n",
    "PATH_TO_Data = '/work3/s174498/concept_random_dataset/'\n",
    "\n",
    "file = PATH_TO_Data + Data + '/' + name + '.pt'\n",
    "random_rep = torch.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = []\n",
    "x = []\n",
    "x.extend(random_rep[j*5:(j+1)*5])\n",
    "x.extend(random_rep[i*5:(i+1)*5])\n",
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE /work3/s174498/concept_random_dataset/wikipedia_split/tensor_wikipedia_split_on_11_1_sets_with_150.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Data = 'wikipedia_split'\n",
    "classifier = 'linear'\n",
    "model_layer = '11'\n",
    "num_random_set = 1\n",
    "num_ex_in_set = 150\n",
    "\n",
    "name = f'tensor_{Data}_on_{model_layer}_{num_random_set}_sets_with_{num_ex_in_set}'\n",
    "PATH_TO_Data = '/work3/s174498/concept_random_dataset/'\n",
    "\n",
    "x = torch.tensor([0, 1, 2, 3, 4])\n",
    "file = PATH_TO_Data + Data + '/' + name + '.pt'\n",
    "print('FILE', file)\n",
    "torch.save(x, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_Data = '/work3/s174498/concept_random_dataset/'\n",
    "Data = 'wikipedia_split'\n",
    "random_data = load_from_disk(PATH_TO_Data + Data)\n",
    "random_text = random_data['complex_sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = random_text\n",
    "model_layer = \"roberta.encoder.layer.11.output.dense\"\n",
    "random_rep = create_embedding(random_text, classifier, model_layer, num_random_set= num_random_set, num_ex_in_set= num_ex_in_set )\n",
    "\n",
    "name = f'tensor_{Data}_on_{model_layer_num}_layer_{num_random_set}_sets_with_{num_ex_in_set}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "datadir = '/work3/s174498/sst2_dataset/'\n",
    "N = 200\n",
    "#test_0_dataset = load_from_disk(datadir + 'test_0_dataset')\n",
    "test_1_dataset = load_from_disk(datadir + 'test_1_dataset')\n",
    "\n",
    "filename = \"/work3/s174498/sst2_dataset/positive\"\n",
    "\n",
    "ds_pos = load_from_disk(filename)\n",
    "ds_pos_text = ds_pos['sentence']\n",
    "\n",
    "filename = \"/work3/s174498/sst2_dataset/test_0_dataset\"\n",
    "ds_neg = load_from_disk(filename)\n",
    "ds_neg_text = ds_neg['sentence']\n",
    "\n",
    "pos = [ds_pos_text[i] for i in list(np.random.choice(len(ds_pos_text),150))]\n",
    "neg = [ds_neg_text[i] for i in list(np.random.choice(len(ds_neg_text),150))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "datadir = '/work3/s174498/concept_random_dataset/'\n",
    "filename = 'tweet_hate/test'\n",
    "ds_hate = load_from_disk(datadir + filename)\n",
    "ds_hate = ds_hate['text']\n",
    "hate = [ds_hate[i] for i in list(np.random.choice(len(ds_hate),200))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "filename = '20_newsgroups/test'\n",
    "ds_news= load_from_disk(datadir + filename)\n",
    "ds_news = ds_news['text']\n",
    "news = [ds_news[i] for i in list(np.random.choice(len(ds_news),150))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits,sensitivity,TCAV = get_preds_tcavs(classifier = 'linear',model_layer='roberta.encoder.layer.11.output.dense',desired_class=1,counter_set = 'wikipedia_split',concept_examples = neg,num_runs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> load RSM /work3/s174498/final/original_head/checkpoint-500\n",
      "roberta.encoder.layer.11.output.dense\n",
      "Linear(in_features=3072, out_features=768, bias=True)\n",
      "calculating cavs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zhome/94/5/127021/speciale/master_project/src/models/hate_tcav/Roberta_model_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/zhome/94/5/127021/speciale/master_project/src/models/hate_tcav/Roberta_model_data.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> GET REPS concept repres (150, 768)\n",
      ">>> calculating logits and grads...\n",
      "/zhome/94/5/127021/speciale/master_project/notebooks\n",
      ">>> FOR LOOP GRADS 200\n",
      ">>> sensitivet\n",
      " [[-0.32946995 -0.3762316  -0.37264585 ... -0.32716873 -0.3995914\n",
      "  -0.3363057 ]\n",
      " [-0.05316321 -0.11972028 -0.18315513 ... -0.07587533 -0.22036487\n",
      "  -0.10244454]\n",
      " [-0.34740585 -0.38986558 -0.377735   ... -0.33894926 -0.40245044\n",
      "  -0.34736216]\n",
      " ...\n",
      " [-0.3007218  -0.35548198 -0.39561194 ... -0.3091061  -0.41288307\n",
      "  -0.33127677]\n",
      " [-0.20628703 -0.26678878 -0.33055857 ... -0.22072682 -0.35390756\n",
      "  -0.24831821]\n",
      " [-0.27626154 -0.33367914 -0.38251525 ... -0.28909042 -0.4015702\n",
      "  -0.31265745]]\n",
      ">>> concetp cavs 175\n",
      "(200, 175)\n",
      "examples length 200\n",
      "TCAV score for the concept: \n",
      "0.16397142857142855 0.005639076491188022\n"
     ]
    }
   ],
   "source": [
    "logits,sensitivity,TCAV = get_preds_tcavs(classifier = 'Founta',desired_class = 0,examples_set = 'random',concept_examples = neg,num_runs=175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> load RSM /work3/s174498/final/original_head/checkpoint-500\n",
      "roberta.encoder.layer.11.output.dense\n",
      "Linear(in_features=3072, out_features=768, bias=True)\n",
      "calculating cavs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zhome/94/5/127021/speciale/master_project/src/models/hate_tcav/Roberta_model_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/zhome/94/5/127021/speciale/master_project/src/models/hate_tcav/Roberta_model_data.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> GET REPS concept repres (200, 768)\n",
      ">>> calculating logits and grads...\n",
      "/zhome/94/5/127021/speciale/master_project/notebooks\n",
      ">>> FOR LOOP GRADS 200\n",
      ">>> sensitivet\n",
      " [[-0.5763484  -0.6256677  -0.6342381  ... -0.61625797 -0.5737675\n",
      "  -0.6444334 ]\n",
      " [-0.5496734  -0.62009275 -0.63021547 ... -0.614389   -0.5422272\n",
      "  -0.6349286 ]\n",
      " [-0.5524504  -0.61900556 -0.62839377 ... -0.6138998  -0.54682565\n",
      "  -0.6349349 ]\n",
      " ...\n",
      " [-0.40301588 -0.47190544 -0.48724315 ... -0.46219224 -0.39935225\n",
      "  -0.48812774]\n",
      " [-0.5646938  -0.6335531  -0.6428068  ... -0.6304109  -0.5566635\n",
      "  -0.6488873 ]\n",
      " [-0.5071938  -0.5824376  -0.5933125  ... -0.58034813 -0.49805397\n",
      "  -0.5964497 ]]\n",
      ">>> concetp cavs 150\n",
      "(200, 150)\n",
      "examples length 200\n",
      "TCAV score for the concept: \n",
      "0.04123333333333332 0.004240151988890126\n"
     ]
    }
   ],
   "source": [
    "logits,sensitivity,TCAV = get_preds_tcavs(classifier = 'Founta',desired_class = 1,examples_set = 'random',concept_examples = hate,num_runs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> load RSM /work3/s174498/final/original_head/checkpoint-500\n",
      "roberta.encoder.layer.11.output.dense\n",
      "Linear(in_features=3072, out_features=768, bias=True)\n",
      "calculating cavs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zhome/94/5/127021/speciale/master_project/src/models/hate_tcav/Roberta_model_data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/zhome/94/5/127021/speciale/master_project/src/models/hate_tcav/Roberta_model_data.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> GET REPS concept repres (150, 768)\n",
      ">>> calculating logits and grads...\n",
      "/zhome/94/5/127021/speciale/master_project/notebooks\n",
      ">>> FOR LOOP GRADS 200\n",
      ">>> sensitivet\n",
      " [[ 0.0460216   0.21050298  0.21091616 ...  0.18030001  0.05713004\n",
      "   0.17740501]\n",
      " [ 0.02055839  0.20223744  0.20846844 ...  0.21574512  0.05785082\n",
      "   0.16677406]\n",
      " [ 0.00779834  0.18219236  0.186719   ...  0.18796147  0.04499415\n",
      "   0.15062419]\n",
      " ...\n",
      " [ 0.2541175   0.4407654   0.4514586  ...  0.44370875  0.29653287\n",
      "   0.40431303]\n",
      " [-0.08421046  0.07827068  0.08002743 ...  0.09341226 -0.04665715\n",
      "   0.04909039]\n",
      " [-0.00531835  0.1702322   0.1763019  ...  0.19970472  0.04050907\n",
      "   0.13665774]]\n",
      ">>> concetp cavs 150\n",
      "(200, 150)\n",
      "examples length 200\n",
      "TCAV score for the concept: \n",
      "0.9708333333333333 0.07802439077337008\n"
     ]
    }
   ],
   "source": [
    "logits,sensitivity,TCAV = get_preds_tcavs(classifier = 'Founta',desired_class = 1,examples_set = 'random',concept_examples = pos,num_runs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('roberta_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c3ec90920587dcd62ca10f98568309ae5fe8dd1757bd16b3e1a83d20ad0c067"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
