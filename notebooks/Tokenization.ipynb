{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5CYHcPO0AhL"
      },
      "source": [
        "# Visualize your ü§ó Hugging Face data\n",
        "#### üõ†Ô∏è Installation and set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JurK8mIH0AhP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from transformers import RobertaTokenizer\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVXUoDKy0AhQ"
      },
      "source": [
        "### üõ´ Data and model preparation\n",
        "#### üè∑Ô∏è Loading a dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "quwoNjNt0AhR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/zhome/94/5/127021/miniconda3/envs/roberta_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Found cached dataset sst2 (/zhome/94/5/127021/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 489.91it/s]\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"sst2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['idx', 'sentence', 'label'],\n",
              "        num_rows: 67349\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['idx', 'sentence', 'label'],\n",
              "        num_rows: 872\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['idx', 'sentence', 'label'],\n",
              "        num_rows: 1821\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For demo sub-sample dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aM29Dj760AhX"
      },
      "outputs": [],
      "source": [
        "small_data_train = dataset['train'].select(range(dataset['train'].num_rows // 10))\n",
        "# alternative methods\n",
        "# dataset[\"train\"].shuffle(seed=42).select([i for i in list(range(100))])\n",
        "small_data_val = dataset['validation'].select(range(dataset['validation'].num_rows // 10)) # dataset[\"validation\"].shuffle(seed=42).select([i for i in list(range(50))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9lYU6nB0AhX"
      },
      "source": [
        "### ‚öôÔ∏è Tokenizing the dataset\n",
        "In a typical NLP workflow, we must first tokenize our dataset.\n",
        "\n",
        "Converting the stream of characters in the text into a stream of defined \"tokens\", which can be anything from a smaller set of characters to words from a vocabulary.\n",
        "\n",
        "We will use a pretrained model, so we inherit its tokenization scheme."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 899k/899k [00:00<00:00, 1.42MB/s] \n",
            "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 456k/456k [00:00<00:00, 863kB/s] \n",
            "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 481/481 [00:00<00:00, 378kB/s]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hide new secretions from the parental units ',\n",
              " 'contains no wit , only labored gags ',\n",
              " 'that loves its characters and communicates something rather beautiful about human nature ',\n",
              " 'remains utterly satisfied to remain the same throughout ',\n",
              " 'on the worst revenge-of-the-nerds clich√©s the filmmakers could dredge up ']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "small_data_train['sentence'][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_text = ['hello world',' hello world', 'hello world.','hello world?',' hello world ','hello world .']\n",
        "test_text2 = ['in store and dog',' in store ','in store ',' in store','in store?','in store.','in store .']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [[0, 179, 1400, 8, 2335, 2], [0, 11, 1400, 1437, 2], [0, 179, 1400, 1437, 2], [0, 11, 1400, 2], [0, 179, 1400, 116, 2], [0, 179, 1400, 4, 2], [0, 179, 1400, 479, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(test_text2, truncation = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [[0, 37265, 92, 3556, 2485, 31, 5, 20536, 2833, 1437, 2], [0, 10800, 5069, 117, 22094, 2156, 129, 6348, 3995, 821, 8299, 1437, 2], [0, 6025, 6138, 63, 3768, 8, 39906, 402, 1195, 2721, 59, 1050, 2574, 1437, 2], [0, 5593, 5069, 19223, 10028, 7, 1091, 5, 276, 1328, 1437, 2], [0, 261, 5, 2373, 13543, 12, 1116, 12, 627, 12, 1396, 11622, 43848, 5739, 5, 17504, 115, 31120, 1899, 62, 1437, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(small_data_train['sentence'][:5])#, truncation = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NY0l8K5o0AhY"
      },
      "outputs": [],
      "source": [
        "    \n",
        "# tokenizer(examples[\"sentence\"], truncation=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tokenized_train = small_train_dataset.map(tokenizer(examples[\"sentence\"], truncation=True), batched=True)\n",
        "tokenized_val = small_val_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPYLcMM00AhZ"
      },
      "source": [
        "We then map the tokenizer over our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:1esurvui) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f1400350bc04ebeaf655b61d8b2294b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">wild-feather-4</strong>: <a href=\"https://wandb.ai/mmfogh/SST2_sentiment_analysis/runs/1esurvui\" target=\"_blank\">https://wandb.ai/mmfogh/SST2_sentiment_analysis/runs/1esurvui</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20221020_140326-1esurvui/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:1esurvui). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29325debe3804955ab8aeb6bf3711715",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0166690305651476, max=1.0))‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/zhome/a6/6/127219/Speciale/master_project/notebooks/wandb/run-20221020_140438-52a9yw3q</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/mmfogh/SST2_sentiment_analysis/runs/52a9yw3q\" target=\"_blank\">expert-pine-5</a></strong> to <a href=\"https://wandb.ai/mmfogh/SST2_sentiment_analysis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/mmfogh/SST2_sentiment_analysis/runs/52a9yw3q?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fc1eed6b210>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from wandb.sdk.integration_utils.data_logging import ValidationDataLogger\n",
        "#from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import RobertaTokenizer, DataCollatorWithPadding, RobertaForSequenceClassification, TrainingArguments, Trainer\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "\n",
        "import wandb\n",
        "wandb.init(project=\"SST2_sentiment_analysis\",\n",
        "            entity=\"mmfogh\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The history saving thread hit an unexpected error (OperationalError('unable to open database file')).History will not be written to the database.\n",
            "Downloading and preparing dataset sst2/default (download: 7.09 MiB, generated: 4.78 MiB, post-processed: Unknown size, total: 11.88 MiB) to /zhome/94/5/127021/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5...\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "[Errno 28] No space left on device: '/zhome/94/5/127021/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5.incomplete'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_function\u001b[39m(examples):\n\u001b[1;32m      2\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer(examples[\u001b[39m\"\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m\"\u001b[39m], truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39msst2\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m small_train_dataset \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshuffle(seed\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\u001b[39m.\u001b[39mselect([i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m))])\n\u001b[1;32m      7\u001b[0m small_val_dataset \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshuffle(seed\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\u001b[39m.\u001b[39mselect([i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m))])\n",
            "File \u001b[0;32m~/miniconda3/envs/roberta_env/lib/python3.9/site-packages/datasets/load.py:1742\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, **config_kwargs)\u001b[0m\n\u001b[1;32m   1739\u001b[0m try_from_hf_gcs \u001b[39m=\u001b[39m path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[1;32m   1741\u001b[0m \u001b[39m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 1742\u001b[0m builder_instance\u001b[39m.\u001b[39;49mdownload_and_prepare(\n\u001b[1;32m   1743\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1744\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1745\u001b[0m     ignore_verifications\u001b[39m=\u001b[39;49mignore_verifications,\n\u001b[1;32m   1746\u001b[0m     try_from_hf_gcs\u001b[39m=\u001b[39;49mtry_from_hf_gcs,\n\u001b[1;32m   1747\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1748\u001b[0m )\n\u001b[1;32m   1750\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[1;32m   1752\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[1;32m   1753\u001b[0m )\n",
            "File \u001b[0;32m~/miniconda3/envs/roberta_env/lib/python3.9/site-packages/datasets/builder.py:793\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_manual_download(dl_manager)\n\u001b[1;32m    792\u001b[0m \u001b[39m# Create a tmp dir and rename to self._output_dir on successful exit.\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m \u001b[39mwith\u001b[39;00m incomplete_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_dir) \u001b[39mas\u001b[39;00m tmp_output_dir:\n\u001b[1;32m    794\u001b[0m     \u001b[39m# Temporarily assign _output_dir to tmp_data_dir to avoid having to forward\u001b[39;00m\n\u001b[1;32m    795\u001b[0m     \u001b[39m# it to every sub function.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m     \u001b[39mwith\u001b[39;00m temporary_assignment(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_output_dir\u001b[39m\u001b[39m\"\u001b[39m, tmp_output_dir):\n\u001b[1;32m    797\u001b[0m \n\u001b[1;32m    798\u001b[0m         \u001b[39m# Try to download the already prepared dataset files\u001b[39;00m\n\u001b[1;32m    799\u001b[0m         downloaded_from_gcs \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/roberta_env/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
            "File \u001b[0;32m~/miniconda3/envs/roberta_env/lib/python3.9/site-packages/datasets/builder.py:763\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare.<locals>.incomplete_dir\u001b[0;34m(dirname)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     tmp_dir \u001b[39m=\u001b[39m dirname \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.incomplete\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 763\u001b[0m     os\u001b[39m.\u001b[39;49mmakedirs(tmp_dir, exist_ok\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    764\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    765\u001b[0m         \u001b[39myield\u001b[39;00m tmp_dir\n",
            "File \u001b[0;32m~/miniconda3/envs/roberta_env/lib/python3.9/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     mkdir(name, mode)\n\u001b[1;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exist_ok \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39misdir(name):\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device: '/zhome/94/5/127021/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5.incomplete'"
          ]
        }
      ],
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"sentence\"], truncation=True)\n",
        "\n",
        "dataset = load_dataset(\"sst2\")\n",
        "\n",
        "small_train_dataset = dataset[\"train\"].shuffle(seed=42).select([i for i in list(range(100))])\n",
        "small_val_dataset = dataset[\"validation\"].shuffle(seed=42).select([i for i in list(range(50))])\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "tokenized_train = small_train_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_val = small_val_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "#model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_inputs = tokenized_val.remove_columns(['label', 'idx'])\n",
        "validation_targets = [tokenized_val.features['label'].int2str(x) for x in tokenized_val['label']]\n",
        "\n",
        "validation_inputs[0], validation_targets[0]\n",
        "\n",
        "validation_logger = ValidationDataLogger(\n",
        "    inputs = validation_inputs[:],\n",
        "    targets = validation_targets\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQTzrUAo0Ahb"
      },
      "source": [
        "In this case, we are loading a pre-trained network to which a custom head has been added for sequence classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "w399ral70Ahb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_uyzm120Ahc"
      },
      "source": [
        "\n",
        "Let's make a function to return the topic prediction from a sample question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RutBkVh80Ahc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def get_topic(sentence, tokenize=tokenizer, model=model):\n",
        "    # tokenize the input\n",
        "    inputs = tokenizer(sentence, return_tensors='pt')\n",
        "    # ensure model and inputs are on the same device (GPU)\n",
        "    #inputs = {name: tensor.cuda() for name, tensor in inputs.items()}\n",
        "    #model = model.cuda()\n",
        "    # get prediction - 10 classes \"probabilities\" (not really true because they still need to be normalized)\n",
        "    with torch.no_grad():\n",
        "        predictions = model(**inputs)[0].cpu().numpy()\n",
        "    # get the top prediction class and convert it to its associated label\n",
        "    top_prediction = predictions.argmax().item()\n",
        "    return dataset['train'].features['label'].int2str(top_prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-JCVK-v0Ahd"
      },
      "source": [
        "We can test our prediction pipeline on a sample sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mTdpxrn40Ahf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'positive'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_topic('Why is cheese so much better with wine?')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSJ6GdUy0Ahg"
      },
      "source": [
        "When we ran our model, we got the answer `Politics & Government`,\n",
        "which doesn't seem quite right for a question about cheese and wine.\n",
        "\n",
        "That's because the model has not been trained yet so the outputs are still random. But at least we have a working pipeline!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICcCHj3Q0Ahh"
      },
      "source": [
        "# üìä Log your data for better visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyQ9hjhj0Ahi"
      },
      "source": [
        "Before we train our model, let's set up some better logging during training.\n",
        "\n",
        "Without the ability to inspect model behavior, it can be hard to debug or understand models.\n",
        "So we'll log a table of information about the model's behavior on the validation set --\n",
        "not just the loss or accuracy, but the inputs and outputs as well.\n",
        "\n",
        "Our data is already in a pandas `DataFrame`, so there's not much we have to do besides\n",
        "slightly reformat them\n",
        "and then use them to define a `ValidationDataLogger` instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "idAYx0Gv0Ahj"
      },
      "outputs": [],
      "source": [
        "from wandb.sdk.integration_utils.data_logging import ValidationDataLogger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['idx', 'sentence', 'label', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 87\n",
              "})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LkYiH5UG0Ahk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'idx': 0, 'sentence': \"it 's a charming and often affecting journey . \"},\n",
              " 'positive')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation_inputs = dataset['test'].remove_columns(['label', 'attention_mask', 'input_ids'])\n",
        "validation_targets = [dataset['test'].features['label'].int2str(x) for x in dataset['test']['label']]\n",
        "\n",
        "validation_inputs[0], validation_targets[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ApItJNfs0Ahk"
      },
      "outputs": [],
      "source": [
        "validation_logger = ValidationDataLogger(\n",
        "    inputs = validation_inputs[:],\n",
        "    targets = validation_targets\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5Ul0ght0Ahl"
      },
      "source": [
        "We can now log our predictions for visualization with `validation_logger.log_predictions(prediction_labels)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9VtWPYs0Ahm"
      },
      "source": [
        "# üëü Training the model and logging to W&B\n",
        "\n",
        "We are now ready to fine-tune the model to solve our task.\n",
        "\n",
        "The Hugging Face [`Trainer` class](https://huggingface.co/transformers/main_classes/trainer.html)\n",
        "lets us easily train a model and is very flexible.\n",
        "\n",
        "**Note:** set `report_to` to `wandb` in `TrainingArguments` to enable logging through W&B."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "N3tAdy840Ahm"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    report_to='wandb',                    # enable logging to W&B\n",
        "    output_dir='topic_classification',    # set output directory\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy='steps',          # check evaluation metrics on a given # of steps\n",
        "    learning_rate=5e-5,                   # we can customize learning rate\n",
        "    max_steps=1000,\n",
        "    logging_steps=100,                    # we will log every 100 steps\n",
        "    eval_steps=500,                       # we will perform evaluation every 1000 steps\n",
        "    eval_accumulation_steps=1,            # report evaluation results after each step\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        "    run_name='my_training_run'            # name of the W&B run\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dPcex31q0Ahn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: WANDB_LOG_MODEL=true\n"
          ]
        }
      ],
      "source": [
        "# automatically log model to W&B at the end\n",
        "%env WANDB_LOG_MODEL=true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcltkepI0Ahn"
      },
      "source": [
        "For more customization, refer to [`TrainingArguments` documentation](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WRoQfOw0Aho"
      },
      "source": [
        "We can optionally define metrics to calculate in addition to the loss through the `compute_metrics` function.\n",
        "\n",
        "Several [metrics](https://huggingface.co/metrics) are readily available from the datasets library to monitor model performance.\n",
        "\n",
        "We'll also use it to log all of our predictions at each evaluation loop,\n",
        "using the `validation_logger`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jfR-wrtL0Aho"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/zhome/a6/6/127219/miniconda3/envs/sent_env/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.023088693618774414,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "Downloading builder script",
              "rate": null,
              "total": 1652,
              "unit": "B",
              "unit_divisor": 1000,
              "unit_scale": true
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a8d5a474ba24ca98c1b730d081f2a75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "import numpy as np\n",
        "\n",
        "accuracy_metric = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # convert predictions from class (0, 1, 2‚Ä¶) to label (Health, Science‚Ä¶)\n",
        "    prediction_labels = [dataset['test'].features['labels'].int2str(x.item())\n",
        "                         for x in predictions]\n",
        "    \n",
        "    # log predictions\n",
        "    validation_logger.log_predictions(prediction_labels)\n",
        "\n",
        "    # metrics from the datasets library have a compute method\n",
        "    return accuracy_metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0ZDUI-60Aho"
      },
      "source": [
        "The `Trainer` handles all the training & evaluation logic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CwxiEfwj0Aho"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,                  # model to be trained\n",
        "    args=args,                    # training args\n",
        "    train_dataset=dataset['train'],\n",
        "    eval_dataset=dataset['test'],\n",
        "    tokenizer=tokenizer,            # for padding batched data\n",
        "    compute_metrics=compute_metrics # for custom metrics\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('roberta_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "2c3ec90920587dcd62ca10f98568309ae5fe8dd1757bd16b3e1a83d20ad0c067"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
