{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer\n",
    "from datasets import load_from_disk, load_metric, Dataset, load_dataset\n",
    "\n",
    "from captum.concept import TCAV\n",
    "from captum.concept._utils.data_iterator import dataset_to_dataloader, CustomIterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = '/work3/s174498/finetuning-sentiment-model-test-head3/checkpoint-500'\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(checkpoint,output_hidden_states = True,return_dict = True,)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.roberta.encoder.layer[0].attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcav = TCAV(model, layers=['roberta.encoder.layer[0]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the text inputs for the model\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer_checkpoint(examples[\"sentence\"], truncation=True)\n",
    "\n",
    "tokenized_test = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hvordan bruger man den her : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor_from_filename(filename):\n",
    "    ds = torchtext.data.TabularDataset(path=filename,\n",
    "                                       fields=[('text', torchtext.data.Field()),\n",
    "                                               ('label', torchtext.data.Field())],\n",
    "                                       format='csv')\n",
    "    const_len = 7\n",
    "    for concept in ds:\n",
    "        concept.text = concept.text[:const_len]\n",
    "        concept.text += ['pad'] * max(0, const_len - len(concept.text))\n",
    "        text_indices = torch.tensor([TEXT.vocab.stoi[t] for t in concept.text], device=device)\n",
    "        yield text_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor_from_filename(filename):\n",
    "    img = Image.open(filename).convert(\"RGB\")\n",
    "    return transform(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hent concept data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_concept(name, id, concepts_path=\"/work3/a174498/sst2_dataset/\"):\n",
    "    concept_path = os.path.join(concepts_path, name) + \"/\"\n",
    "    dataset = CustomIterableDataset(get_tensor_from_filename, concept_path)\n",
    "    concept_iter = dataset_to_dataloader(dataset)\n",
    "\n",
    "    return Concept(id=id, name=name, data_iter=concept_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_concept(name, id, concepts_path=\"data/tcav/text-sensitivity\"):\n",
    "    dataset = CustomIterableDataset(get_tensor_from_filename, concepts_path)\n",
    "    concept_iter = dataset_to_dataloader(dataset, batch_size=1)\n",
    "    return Concept(id=id, name=name, data_iter=concept_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcav.interpret(tokenized_test, experimental_sets=experimental_sets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('roberta_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c3ec90920587dcd62ca10f98568309ae5fe8dd1757bd16b3e1a83d20ad0c067"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
